---
typora-copy-images-to: ${filename}.assets
typora-root-url: .\
mathjax: true
---



# 1 全局光照

DDGI world probe + Lumen screen probe

screen probe 放置于直接可见表面，处理着色点一次弹射收到的irradiance。world probe以均匀格点形式分布于世界空间，通过球面上均匀采样收集周围光场信息。screen probe 的光线交点着色除了直接光照还会额外采样world probe，以及 world probe 的光线交点着色会采样上一帧world probe的irradiance，这样多帧下来会得到近似无限反弹的效果。

着色点通过插值周围4个probe生成screen irradiance。

## 1.1 world probe

分布上使用均匀格点分布，可以有多层级，第 0 层级全部处于激活状态，后续层级是在上一层级的grid内继续划分，会有一个以相机为中心的激活区域。

### 1.1.1 spatial filter

光线方向均匀分布在 8x8 八面体图。执行 3x3x3 区域、同一个八面体 texel 内的光线进行filter。在filter前，执行可见性判断。

可见性判断，这里的可见性判断非常简单且近似。
<img src="/项目经历.assets/image-20241113210807460.png" alt="image-20241113210807460" style="zoom: 50%;" />

假设 ray起点到 ray_neighbor中点的距离 dmid，并从当前**probe中获取该方向上**的光线样本长度 lmid 。
当这dmid超过lmid一定阈值时，则视为不可见，阈值使用grid最小距离控制。如下判断`(dmid−lmid) >= 0.05∗min_dist`

### 1.1.2 temporal filter

激活区域随着相机移动，先重投影到当前帧，然后执行时序累积

### 1.1.3 probe sampling

定位包含着色点的8个world probe，执行三线性插值，权重设计为：

- 基础的线性插值的距离权重
- visibility权重，基于vsm
  每层grid大小都不相同，visibility map中存储的是归一化的hit距离。假设当前层grid最大距离为 `max_dist` ，某一光线的hit距离为 `hit_dist` ，那么 visibility map 统计的是 `clamp(hit_dis/max_dis, 0.0, 1.0)` 的一阶矩、二阶矩。
  - 着色点到插值probe的距离为 dist，进行归一化
  - 使用visibility map中信息求着色点到插值probe上的距离variance与mean
  - 基于variance与mean，计算vis下的visibility权重

## 1.2 screen probe

参考 AMD GI-1.0 的实现。算法核心思路是将每帧实时更新的probe radiance 与 probe 的radiance cache 解耦，可以使用更低的实时更新开销通过时序累积来达到高分辨率的probe radiance cache。例如 16x16 tile 放置一个 probe，通过 4 帧累积到每 8x8 tile一个probe 的分辨率。

第二点是在spatial filter时拒绝掉超过cell_size距离，cell_size 是基于到相机距离的启发式参数，近似理解为屏幕probe tile 大小在probe位置处的投影大小。

### 1.2.1 算法流程-screen probe

#### 1.2.1.1 temporal upscale

当前帧tile变换到上一帧，得到上一帧probe，然后在当前帧tile内的像素上执行匹配测试，放置到最匹配的位置。匹配测试：

- 拒绝掉超过cell_size以及法线差异大的，使用距离作为评分，找到距离最近的。高16为距离，低16位为tile内线程索引，使用`atomicMin` 即可得到距离最近的位置
  ```glsl
  uint probe_score = ((f32tof16(distance(probe_pos, world_pos) / cell_size) << 16) | local_index);
  atomicMin(lds_reprojection[probe_segment], probe_score);
  ```

- 重投影radiance，重映射为当前帧位置指向上一帧交点的光线方向，并在shared memory中累积8x8 oct texel的radiance
  ```c
  vec3 hit_point       = probe_pos + probe_direction * probe_radiance.w;
  vec3 reprojected_dir = hit_point - world_pos; // 重投影光线方向
  float reprojected_len = length(reprojected_dir);
  // 使用reprojected_dir映射到当前帧cell上，并累积相应probe_radiance
  vec2 remap_oct_uv = map_to_oct(reprojected_dir);
  uvec2 remap_cell = remap_oct_uv * probe_size;
  uint remap_cell_index = remap_cell.x + remap_cell.y * probe_size;
  atomicAdd(lds_radiance_acc[remap_cell_index], probe_radiance);  // 累积 radiance
  atomicAdd(lds_radiance_count[remap_cell_index], 1);             // 记录样本数量
  ```

#### 1.2.1.2 放置probe

在 spawn tile 内使用 halton 序列选择放置位置

#### 1.2.1.3 采样光线样本、光追

重要性采样：使用重投影的 probe radiance 为生成probe构建 CDF，L_i * pdf ，执行重要性采样，为选择的cell生成光线

对于去遮挡区域，退化为 cosine 权重的重要性采样

在得到radiance之后，使用 L_i * brdf 构建CDF，使用两趟算法

1. 自下而上，按照二叉树结构进行层层累积，每个子树根节点是子结点之和，且将根节点的值写入右子树子结点。这样可以得到每个子树的和
2. 自上而下，计算前缀和。每个子树根节点的前缀和为 左子树之和 + 右子树的前缀和

```c++
void prefix_scan_sum(float pdf, uint local_id)
{
    uint stride;
    group_cdf[local_id] = pdf;
    memoryBarrierShared(); barrier();

    uint sample_count = uint(get_probe_sample_count());
    pdf = group_cdf[sample_count - 1];
    memoryBarrierShared(); barrier();

    for (stride = 1; stride <= (sample_count >> 1); stride <<= 1) {
        if (local_id < sample_count / (2 * stride))
            group_cdf[2 * (local_id + 1) * stride - 1] += group_cdf[(2 * local_id + 1) * stride - 1];
        memoryBarrierShared(); barrier();
    }

    if (local_id == 0) group_cdf[sample_count - 1] = 0.0f;
    memoryBarrierShared(); barrier();

    for (stride = (sample_count >> 1); stride > 0; stride >>= 1)
    {
        if (local_id < sample_count / (2 * stride)) {
            float tmp = group_cdf[(2 * local_id + 1) * stride - 1];
            group_cdf[(2 * local_id + 1) * stride - 1] = group_cdf[2 * (local_id + 1) * stride - 1];
            group_cdf[2 * (local_id + 1) * stride - 1] += tmp;
        }
        memoryBarrierShared(); barrier();
    }

    pdf += group_cdf[sample_count - 1];
    memoryBarrierShared(); barrier();

    group_cdf[local_id] /= max(pdf, 1e-5f);
    memoryBarrierShared(); barrier();
}
```



#### 1.2.1.4 radiance blend and filter

同样在 radiance blend 阶段需要在 shared memory 中执行 radiance 累积

```c++
if (previous_radiance.w > 0.0f) {
    float lumaA = luminance(radiance.xyz);
    float lumaB = luminance(previous_radiance.xyz);
    // Shadow-preserving biased temporal hysteresis (inspired by: https://www.youtube.com/watch?v=WzpLWzGvFK4&t=630s)
    float temporal_blend = squared(clamp(max(lumaA - lumaB - min(lumaA, lumaB), 0.0f) / max(max(lumaA, lumaB), 1e-4f), 0.0f, 0.95f));
    radiance = lerp(radiance, previous_radiance, temporal_blend);
}
```

7x7 filter 需要查找最近有效的probe，为此构建mipmap加速查找

### 1.2.2 screen irradiance

#### 1.2.2.1 插值 screen probe

probe tile 范围内抖动，否则出现明显的色块artifact

查找最近的 probe，基于view z 的相对差距以及法线差异的权重

```c++
auto view_z_normal_weight(float view_z, vec3 normal, float probe_view_z, vec3 probe_normal) -> float
{
    float weight = clamp(1.0 - abs(probe_view_z - view_z) / abs(view_z), 0.0, 1.0);
    weight *= max(dot(normal, probe_normal), 0.0);
    weight = pow(weight, 8);
    return weight;
}
```

#### 1.2.2.2 降噪

时序累积，记录有效样本数量

根据有效样本数量确定 spatial filter 的半径

## 1.3 Reflection





# 2 Effect Cache

![image-20241113224803871](/项目经历.assets/image-20241113224803871.png)

```c++
struct Surface_Cache_Coord
{
    uint32_t island_index;
    uint32_t resloution : 4;
    uint32_t block_x : 12;
    uint32_t block_y : 12;
};
struct Grid_Cache_Coord
{
    uint32_t level : 5;
    uint32_t grid_x : 19;
    uint32_t grid_y : 19;
    uint32_t grid_z : 19;
};
```

首先effect cache的提出是为了在面向多view的云渲染场景下，通过维护一份cache用来缓存与视角无关的计算，这样同一cache位置只会计算一次，然后多view之间可以共享与视角无关的计算。

effect cache 管线需要对场景几何的参数化，划分成cluster，cluster展开到uv空间，cluster index 以及其texture space 下的uv坐标能够唯一表示表面上的任一点。通过这些信息可以发出cache请求。

这个相当于是一个texture space下cache机制，但想要表示整个场景的texture space在存储上是不可能的。



## 2.1 基于GPU hash table的cache寻址

<img src="/项目经历.assets/image-20241114212812605.png" alt="image-20241114212812605" style="zoom: 50%;" />

hash table 存放的是 cache entry<key, value>，以内存块

- bucket 数组记录

一种开放寻址与拉链法的折衷

### 2.1.1 super node 分配

基于并发栈的分配，将一个buffer划分为多个super node，栈中记录super node index

栈顶指针 `top` 指向首个非空元素的相邻空元素。

对于普通的并发栈数据结构的实现，需要解决 [ABA problem](https://en.wikipedia.org/wiki/ABA_problem)，但由于本文栈的特性——没有重复元素，所以实现起来比较简单。

contention处理：当多个线程同时竞争同一top指针时，一次迭代仅会完成一个线程的操作。

- 使用atomicAdd得到target_top，即目标操作位置。
  目标位置在执行操作需要满足要求，push操作目标位置需要为空，pop操作目标位置需要不为空。但由于多线程同时操作，可能会出现目标操作位置被其他操作导致不能满足条件。
- 当同一top存在多个线程竞争时，使用atomicCompSwap迭代执行直至目标位置满足要求，一次迭代只会有其中一个线程完成操作。 

```c++
// deallocate会调用栈push操作，实现比较简单
void push(uint value)
{
    uint target_top = atomicAdd(top, 1);
    if (target_top >= STACK_SIZE) return;    // 栈满
    while(atomicCompSwap(
            concurrent_stack[target_top],
            EMPTY_NODE_INDEX,
            value
        ) != EMPTY_NODE_INDEX
    );
}

// allocate会调用栈pop操作，实现比较复杂
uint pop()
{
    uint target_top = atomicAdd(top, -1) - 1;
    if (target_top >= STACK_SIZE) return EMPTY_NODE_INDEX;   // 栈空，溢出
    while (true) {
        uint value = concurrent_stack[target_top]; // 使用atomicAnd(, 0xFFFFFFFF)
        if (value != EMPTY_NODE_INDEX
            && atomicCompSwap(
                concurrent_stack[target_top],
                value,
                EMPTY_NODE_INDEX
            ) == value
        ) {
            return value;
        }
    }
    return EMPTY_NODE_INDEX;
```



### 2.1.2 协作模式

hash table 的查找过程不是每个线程独立负责一个cache key的查找，而是将subgroup划分成super node大小的组，一组查找一个cache key

提高并行性，尽可能让一个warp的线程执行相同的指令，访问相邻的数据。需要借助glsl的subgroup指令

- `uvec4 subgroupBallot(bool value)`：subgroup中的每个invocation贡献1bit，value变量 true对应bit值 1、反之对应bit值0。invocation 索引与位索引对应，未激活invocation对应bit值 0。对于Nvidia显卡，subgroup size为32，因此32~127恒为0.
- `T subgroupShuffle(T value, uint index)`：拷贝 invocation 的value变量，要求其 gl_SubgroupInvocationID 为 index
- `uint subgroupBallotFindLSB(uvec4 value)`：返回value中不为0的最低位索引（从1开始，0表示value全为0）。只会处理低 gl_SubgroupSize 部分。

原子操作：

- [uint atomicCompSwap(inout uint mem, uint compare, uint data)](https://registry.khronos.org/OpenGL-Refpages/gl4/html/atomicCompSwap.xhtml) ：mem与compare相等时，data写入mem。否则无操作。返回值是mem操作前的原值。
  因此当返回值==compare时，data写入mem

```c++
auto tile_operation(uint64_t key) -> void
{
    bool is_to_operate = key != EMPTY_KEY;
    key &= 0x3FFFFFFFFFFFFFFF;      // 去除最高两位保留位
    uint bucket = hash_function(key);
    uint lane_id = gl_SubgroupInvocationID;
    uint tile_lane_id = lane_id % TILE_SIZE;
    uint tile_id = lane_id / TILE_SIZE;
 
    uvec4 ballot = subgroupBallot(is_to_operate);
    uint work_queue = ballot.x;
    uint tile_bit_offset = 1 << TILE_SIZE;
    uint tile_mask = tile_bit_offset - 1;
    uint tile_work_queue = (work_queue >> (tile_id * tile_bit_offset)) & tile_mask;
    uint last_tile_work_queue = 0;
    uint super_node_index = EMPTY_NODE_INDEX;
    uint next = EMPTY_NODE_INDEX;
    while (tile_work_queue) {
        // The target of tile iteration
        uint target_tile_lane = subgroupBallotFindLSB(uvec4(tile_work_queue)) - 1;
        uint target_lane = tile_id * TILE_SIZE + target_tile_lane;
        uint64_t target_key = subgroupShuffle(key, target_lane);
        uint target_bucket = subgroupShuffle(bucket, target_lane);
        // The super node which next tile iteration would execute on
        super_node_index = (last_tile_work_queue != tile_work_queue)
                                ? fetch_bucket_header(target_bucket)        // Start new operation
                                : fetch_bucket_next(target_bucket, next);   // Move to next super node
 
        // Access hash table by the current invocation
        uint64_t search_key = fetch_key(target_bucket, super_node_index, tile_lane_id); // atomic保证coherent
        search_key &= ~LOCK_MASK;   // 去除次高位(锁)保留位，确保比较操作不受加锁影响，注意buffer中的key没有被改变，因此不会影响后续锁操作
 
        // copy the next pointer from last lane of tile
        uint next = subgroupShuffle(search_key, (tile_id + 1) * TILE_SIZE - 1);
         
        // 执行实际的操作
        {
            // ...
        }
 
        // update work queue
        last_tile_work_queue = tile_work_queue;
        ballot = subgroupBallot(is_to_operate);
        work_queue = ballot.x;
        tile_work_queue = (work_queue >> (tile_id * tile_bit_offset)) & tile_mask;
    }
}
```

### 2.1.3 操作

- delete 操作仅仅将对应entry标记为删除，再使用一个compact pass，将数据紧凑



由于 64bit key，没办法使用原子操作处理一个对键值，所以将最高位作为加锁标记

```c++
auto lock_update_value(DAC_KEY_TYPE origin_key, DAC_KEY_TYPE key, DAC_VALUE_TYPE value, uint index, uint tile_lane_id) -> bool
{
    DAC_KEY_TYPE search_key = origin_key;
    search_key &= ~DAC_LOCK_MASK;
    DAC_KEY_TYPE lock_key = key | DAC_LOCK_MASK;
    while (search_key == (origin_key & ~DAC_LOCK_MASK)) {
        search_key = atomicCompSwap(dac_block_pool[index].key_list[tile_lane_id], origin_key, lock_key); // lock
        if (origin_key == search_key) {
            atomicExchange(dac_block_pool[index].value_list[tile_lane_id], value);
            atomicCompSwap(dac_block_pool[index].key_list[tile_lane_id], lock_key, key); // unlock
            return true;
        }
        // Failed to lock, try again
        search_key &= ~DAC_LOCK_MASK;
    }
    // The target slot is taken away by another thread.
    return false;
}
```

## 2.2 存储管理

texel block 为单位，使用并发栈进行管理

### 2.2.1 生命周期管理

- LRU 回收
- 每隔几帧更新

k-selection 算法

算法需要记录每个texel block所属bucket的数组 `bucket_records` ，长度与texel block长度相同；记录每个 bucket 持有元素数量的数组 `bucket_counters` ，长度为bucket数量。

1. 确定bucket区间。这一步需要确定输入数据的min、max

   - 使用一个单独的pass遍历输入数据得到。或者
   - 设定好最大帧数 F，使用 0~F

2. 数据投影到bucket。需要遍历输入数据，并对bucket计数。投影过程，应该反过来，从大到小排列，方便后面求前缀和。

   

3. 确定候选bucket

   1. 需要计算 bucket_counters 数组的前缀和，需要遍历 bucket_counters 数组
      似乎只能使用一个subgroup遍历计算
   2. 定位候选bucket。应该已经可以在遍历中找到啊

4. 更新min、max进入下一次迭代
   这里也可以拷贝到新数组中。step 2投影中，记录下来投影的目标bucket以及元素地址。当发现是候选bucket时，就将元素拷贝到新数组

   

为了能够在一个pass中完成，step 3需要为每个workgroup计算一次。似乎没必要多个workgroup。

多workgroup是否可以加快？

- step 2，多workgroup可以加快投影速度

  - 但后续步骤需要投影完成，多workgroup应该没办法保证一个同步点

  - 如果拆分为单独的pass，虽然可以确保在后续步骤之前完成投影，但如何确定迭代的结束时机？传回少量数据？

    实测，多workgroup性能要明显优于单workgroup，在texel_block 数量非常大时，开销会很大:

    - 128 x 128 个 texel block，开销有 0.22 ms
    - 512 x 512 个 texel block，开销有3.5 ms以上。



### 2.2.2 难点

并发栈会发生多个线程为同一个cache entry申请存储，导致申请数量远超所需数量而栈溢出。解决方案是使用一个超大的indirect

stack，实际申请的是indirect index，之后再为indirect index分配实际的block index

hash table的操作比较费，无法做到即时查询，因此为每个view存一份查找表，只需要访问hash table因此，后续直接查表。

## 2.3 实现了一个基础的shading

