

<!DOCTYPE html>
<html lang="en" data-default-color-scheme=auto>



<head>
  <meta charset="UTF-8">

  <link rel="apple-touch-icon" sizes="76x76" href="/img/fluid.png">
  <link rel="icon" href="/img/fluid.png">
  

  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=5.0, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="author" content="John Doe">
  <meta name="keywords" content="GPU, Performance">
  
    <meta name="description" content="1 Life of triangle [1]![NVIDIA’s logical pipeline](&#x2F;images&#x2F;Rendering Blogs&#x2F;Profile&#x2F;GPU Logic.assets&#x2F;fermipipeline.png) 1.1 GPUs are super parallel work distributors为什么需要这些复杂性？">
<meta property="og:type" content="article">
<meta property="og:title" content="GPU Logic">
<meta property="og:url" content="http://example.com/2024/11/22/Rendering%20Blogs/Profile/GPU%20Logic/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:description" content="1 Life of triangle [1]![NVIDIA’s logical pipeline](&#x2F;images&#x2F;Rendering Blogs&#x2F;Profile&#x2F;GPU Logic.assets&#x2F;fermipipeline.png) 1.1 GPUs are super parallel work distributors为什么需要这些复杂性？">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="http://example.com/images/Rendering%20Blogs/Profile/GPU%20Logic.assets/pasted-image-0-8-1024x246.png">
<meta property="article:published_time" content="2024-11-22T02:26:59.836Z">
<meta property="article:modified_time" content="2024-11-24T10:37:13.377Z">
<meta property="article:author" content="John Doe">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:image" content="http://example.com/images/Rendering%20Blogs/Profile/GPU%20Logic.assets/pasted-image-0-8-1024x246.png">
  
  
  
  <title>GPU Logic - Hexo</title>

  <link  rel="stylesheet" href="https://lib.baomitu.com/twitter-bootstrap/4.6.1/css/bootstrap.min.css" />



  <link  rel="stylesheet" href="https://lib.baomitu.com/github-markdown-css/4.0.0/github-markdown.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/hint.css/2.7.0/hint.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css" />



<!-- 主题依赖的图标库，不要自行修改 -->
<!-- Do not modify the link that theme dependent icons -->

<link rel="stylesheet" href="//at.alicdn.com/t/c/font_1749284_5i9bdhy70f8.css">



<link rel="stylesheet" href="//at.alicdn.com/t/c/font_1736178_k526ubmyhba.css">


<link  rel="stylesheet" href="/css/main.css" />


  <link id="highlight-css" rel="stylesheet" href="/css/highlight.css" />
  
    <link id="highlight-css-dark" rel="stylesheet" href="/css/highlight-dark.css" />
  




  <script id="fluid-configs">
    var Fluid = window.Fluid || {};
    Fluid.ctx = Object.assign({}, Fluid.ctx)
    var CONFIG = {"hostname":"example.com","root":"/","version":"1.9.8","typing":{"enable":true,"typeSpeed":70,"cursorChar":"_","loop":false,"scope":[]},"anchorjs":{"enable":true,"element":"h1,h2,h3,h4,h5,h6","placement":"left","visible":"hover","icon":""},"progressbar":{"enable":true,"height_px":3,"color":"#29d","options":{"showSpinner":false,"trickleSpeed":100}},"code_language":{"enable":true,"default":"TEXT"},"copy_btn":true,"image_caption":{"enable":true},"image_zoom":{"enable":true,"img_url_replace":["",""]},"toc":{"enable":true,"placement":"right","headingSelector":"h1,h2,h3,h4,h5,h6","collapseDepth":0},"lazyload":{"enable":true,"loading_img":"/img/loading.gif","onlypost":false,"offset_factor":2},"web_analytics":{"enable":false,"follow_dnt":true,"baidu":null,"google":{"measurement_id":null},"tencent":{"sid":null,"cid":null},"leancloud":{"app_id":null,"app_key":null,"server_url":null,"path":"window.location.pathname","ignore_local":false},"umami":{"src":null,"website_id":null,"domains":null,"start_time":"2024-01-01T00:00:00.000Z","token":null,"api_server":null}},"search_path":"/local-search.xml","include_content_in_search":true};

    if (CONFIG.web_analytics.follow_dnt) {
      var dntVal = navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack;
      Fluid.ctx.dnt = dntVal && (dntVal.startsWith('1') || dntVal.startsWith('yes') || dntVal.startsWith('on'));
    }
  </script>
  <script  src="/js/utils.js" ></script>
  <script  src="/js/color-schema.js" ></script>
  


  
<meta name="generator" content="Hexo 7.3.0"></head>


<body>
  

  <header>
    

<div class="header-inner" style="height: 70vh;">
  <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand" href="/">
      <strong>Fluid</strong>
    </a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/" target="_self">
                <i class="iconfont icon-home-fill"></i>
                <span>Home</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/archives/" target="_self">
                <i class="iconfont icon-archive-fill"></i>
                <span>Archives</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/categories/" target="_self">
                <i class="iconfont icon-category-fill"></i>
                <span>Categories</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/tags/" target="_self">
                <i class="iconfont icon-tags-fill"></i>
                <span>Tags</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/about/" target="_self">
                <i class="iconfont icon-user-fill"></i>
                <span>About</span>
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search">
              <i class="iconfont icon-search"></i>
            </a>
          </li>
          
        
        
          <li class="nav-item" id="color-toggle-btn">
            <a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle">
              <i class="iconfont icon-dark" id="color-toggle-icon"></i>
            </a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

  

<div id="banner" class="banner" parallax=true
     style="background: url('/img/default.png') no-repeat center center; background-size: cover;">
  <div class="full-bg-img">
    <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
      <div class="banner-text text-center fade-in-up">
        <div class="h2">
          
            <span id="subtitle" data-typed-text="GPU Logic"></span>
          
        </div>

        
          
  <div class="mt-3">
    
    
      <span class="post-meta">
        <i class="iconfont icon-date-fill" aria-hidden="true"></i>
        <time datetime="2024-11-22 10:26" pubdate>
          November 22, 2024 am
        </time>
      </span>
    
  </div>

  <div class="mt-1">
    
      <span class="post-meta mr-2">
        <i class="iconfont icon-chart"></i>
        
          5.6k words
        
      </span>
    

    
      <span class="post-meta mr-2">
        <i class="iconfont icon-clock-fill"></i>
        
        
        
          47 mins
        
      </span>
    

    
    
  </div>


        
      </div>

      
    </div>
  </div>
</div>

</div>

  </header>

  <main>
    
      

<div class="container-fluid nopadding-x">
  <div class="row nomargin-x">
    <div class="side-col d-none d-lg-block col-lg-2">
      

    </div>

    <div class="col-lg-8 nopadding-x-md">
      <div class="container nopadding-x-md" id="board-ctn">
        <div id="board">
          <article class="post-content mx-auto">
            <h1 id="seo-header">GPU Logic</h1>
            
            
              <div class="markdown-body">
                
                <h1 id="1-Life-of-triangle-1"><a href="#1-Life-of-triangle-1" class="headerlink" title="1 Life of triangle [1]"></a>1 Life of triangle <a href="#%5B1%5D">[1]</a></h1><p>![NVIDIA’s logical pipeline](&#x2F;images&#x2F;Rendering Blogs&#x2F;Profile&#x2F;GPU Logic.assets&#x2F;fermipipeline.png)</p>
<h2 id="1-1-GPUs-are-super-parallel-work-distributors"><a href="#1-1-GPUs-are-super-parallel-work-distributors" class="headerlink" title="1.1 GPUs are super parallel work distributors"></a>1.1 GPUs are super parallel work distributors</h2><p>为什么需要这些复杂性？在图形渲染中，我们需要处理数据扩展 (data amplification) 的问题，这会带来大量不确定的工作负载。每个 draw call 可能生成不同数量的三角形。裁剪后的顶点数量可能与最初的三角形数量不同。在背面剔除和深度剔除之后，不同的三角形可能生成不同的像素。</p>
<p>因此，现代GPU让它们的基本图元（三角形、线、点）遵循的是逻辑流水线，而不是物理流水线。在早期（G80统一架构之前，如DX9硬件、PS3、Xbox360），流水线在芯片上通过不同的阶段体现，工作依次通过这些阶段处理。G80架构基本上对部分单元进行了复用，可以根据负载在顶点着色器和片段着色器之间切换，但仍然以串行方式处理图元、光栅化等。而从Fermi架构开始，流水线变得完全并行，这意味着芯片通过复用多个内部引擎实现了逻辑流水线（即三角形经过的各个步骤）。</p>
<p>假设有两个三角形A和B。它们可能处于不同的逻辑流水线步骤中。例如，A已经被变换，正在进行光栅化。一些像素可能在执行fragment shader，一些像素可能被深度缓冲剔除（Z-cull），还有一些像素可能已经写入帧缓冲区，而还有一些可能仍在等待。同时，三角形B可能在提取顶点数据。因此，尽管每个三角形都需要经过这些逻辑步骤，但许多三角形生命周期的不同阶段可以同时被处理。整个draw call任务被拆分为许多较小的任务，甚至是子任务，这些任务可以并行运行。每个任务都会根据可用的资源进行调度，这种调度不限于某种特定类型的任务（例如顶点着色和片段着色可以并行进行）。</p>
<p>可以把这想象成一条分叉的河流。并行的pipeline stream是彼此独立的，每条pipeline都有自己的时间线，有些pipeline可能分支更多。如果我们用颜色对GPU中的单元进行编码，标记它们当前正在处理的三角形或draw call，那么整个系统就会像一片多彩的“闪烁灯”景象 :)</p>
<h2 id="1-2-GPU-architecture"><a href="#1-2-GPU-architecture" class="headerlink" title="1.2 GPU architecture"></a>1.2 GPU architecture</h2><p>![GPU architecture](&#x2F;images&#x2F;Rendering Blogs&#x2F;Profile&#x2F;GPU Logic.assets&#x2F;fermipipeline_maxwell_gpu.png)</p>
<p>由于 Fermi 架构的 NVIDIA GPU 拥有相似的基本架构设计，其中核心部分是一个管理所有任务的 <strong>Giga Thread Engine</strong>。GPU 被划分为多个 <strong>GPC（Graphics Processing Cluster，图形处理簇）</strong>，每个 GPC 包含多个 <strong>SM（Streaming Multiprocessor，流式多处理器）</strong> 和一个 <strong>Raster Engine（光栅引擎）</strong>。在这些组件之间有大量的互联结构，其中最为重要的是 <strong>Crossbar（交叉开关）</strong>，它允许任务在 GPC 或其他功能单元（例如 <strong>ROP（Render Output Unit，渲染输出单元）</strong> 子系统）之间迁移。</p>
<p>程序员编写的任务（例如着色器程序的执行）实际上是由 SM 来完成的。SM 包含许多 <strong>Core（核心）</strong>，这些核心负责执行线程的数学运算。例如，一个线程可以对应于一个顶点着色器或像素着色器的调用。这些核心以及其他单元由 <strong>Warp Scheduler（Warp 调度器）</strong> 驱动，每个 Warp 调度器管理一组 32 个线程（称为一个 Warp），并将需要执行的指令交给 <strong>Dispatch Unit（分发单元）</strong>。指令的逻辑由调度器处理，而核心本身并不负责逻辑计算。核心接收到的指令类似于“<em>“sum register 4234 with register 4235 and store in 4230</em>”。相比之下，GPU 的核心显得相对“简单”，而 CPU 的核心则更“智能”。GPU 将智能设计集中在更高的架构层面，协调整个系统（甚至多个系统）的工作。</p>
<p>GPU 上这些单元的具体数量（例如每个 GPC 包含多少个 SM，每个 GPU 有多少个 GPC）取决于具体的芯片配置。</p>
<h2 id="1-3-The-logical-pipeline"><a href="#1-3-The-logical-pipeline" class="headerlink" title="1.3 The logical pipeline"></a>1.3 The logical pipeline</h2><p>![The logical pipeline](&#x2F;images&#x2F;Rendering Blogs&#x2F;Profile&#x2F;GPU Logic.assets&#x2F;fermipipeline_begin.png)</p>
<p>为简化起见，省略了一些细节。我们假设 drawcall 引用了一些已经填充好数据的 index- and vertex-buffer，这些缓冲区存储在 GPU 的 DRAM 中，并且仅使用 VS 和 PS：</p>
<ol>
<li><p>程序在图形 API中发起 drawcall。该调用最终会到达驱动程序，驱动程序对调用进行一些合法性验证，并将命令以 GPU 可读取的编码形式插入到 <strong>pushbuffer（推送缓冲区）</strong> 中。在此过程中，CPU 端可能出现许多瓶颈，因此程序员需要合理使用 API，并采用能充分利用现代 GPU 性能的技术。</p>
</li>
<li><p>一段时间后或显式的“flush”调用，驱动程序在 pushbuffer 中积累了足够的工作量，将其发送给 GPU 进行处理（这一过程可能需要操作系统的部分参与）。GPU 的 <strong>Host Interface（主机接口）</strong> 接收到这些命令，并通过 <strong>Front End（前端）</strong> 进行处理。</p>
</li>
<li><p>接着，工作分发开始于 <strong>Primitive Distributor（图元分发器）</strong>，通过处理 index buffer 中的索引数据生成三角形工作批次，并将其分发到多个 <strong>GPC</strong>。</p>
<p>![The logical pipeline](&#x2F;images&#x2F;Rendering Blogs&#x2F;Profile&#x2F;GPU Logic.assets&#x2F;fermipipeline_sm.png)</p>
</li>
<li><p>在 <strong>GPC（图形处理簇）</strong> 内，一个 <strong>SM（流式多处理器）</strong> 的 <strong>Poly Morph Engine（多边形形变引擎）</strong> 负责从三角形索引中提取顶点数据（即Vertex Fetch）</p>
</li>
<li><p>完成顶点数据的提取后，<strong>SM</strong> 内会调度一个由 32 个线程组成的 <strong>Warp（线程束）</strong> 来处理这些顶点数据。</p>
</li>
<li><p><strong>SM</strong> 的 <strong>Warp 调度器（Warp Scheduler）</strong> 会按照顺序为整个 Warp 发出指令。这些线程以 lock-step 执行每条指令，但如果某些线程无需执行某条指令，则它们可以被单独屏蔽。屏蔽线程的情况可能包括：</p>
<ul>
<li><strong>例 1</strong>：当前指令属于 “if (true)” 分支，但某个线程的数据条件计算结果为 “false”；</li>
<li><strong>例 2</strong>：某个线程已经满足了循环终止条件，而其他线程尚未满足。</li>
</ul>
<p>因此，当着色器中出现大量分支分歧（<strong>branch divergence</strong>）时，将显著增加 Warp 中所有线程的执行时间。</p>
<p>需要注意的是，线程无法独立推进，它们只能以 Warp 为单位共同推进！不过，Warp 之间是相互独立的。</p>
</li>
<li><p>Warp 的一条指令可能一次完成，也可能需要多个调度周期。例如，在 <strong>SM</strong> 中，处理 <strong>load&#x2F;store</strong> 操作的单元通常比处理基本数学运算的单元要少。</p>
</li>
<li><p>由于某些指令（特别是内存加载）需要更长的时间来完成，<strong>Warp 调度器</strong> 会切换到其他不需要等待内存的 Warp。这正是 <strong>GPU</strong> 克服内存读取延迟的关键机制：通过切换warp，隐藏延迟并减少等待时间。为了实现快速切换，调度器管理的所有线程在 <strong>寄存器文件（register file）</strong> 中拥有各自独立的寄存器。如果某个着色器程序需要的寄存器较多，那么可容纳的线程&#x2F;Warps 就会减少。这意味着可供切换的 Warp 也减少，从而在等待指令完成（尤其是内存加载）期间，可执行的有效工作量也会减少。这种<strong>寄存器资源的限制</strong>可能会导致效率下降。</p>
<p>![The logical pipeline](&#x2F;images&#x2F;Rendering Blogs&#x2F;Profile&#x2F;GPU Logic.assets&#x2F;fermipipeline_memoryflow.png)</p>
</li>
<li><p>当 <strong>Warp</strong> 完成所有顶点着色器的指令后，其结果将由 <strong>视口变换</strong> 进行处理。随后，三角形将在 clip space volume 内进行裁剪，准备进入光栅化阶段。 在这一过程中，我们使用 <strong>L1 缓存</strong> 和 <strong>L2 缓存</strong> 来存储并管理各个任务之间通信的数据。</p>
<p>![The logical pipeline](&#x2F;images&#x2F;Rendering Blogs&#x2F;Profile&#x2F;GPU Logic.assets&#x2F;fermipipeline_raster.png)</p>
</li>
<li><p>现在到了令人兴奋的部分，我们的三角形即将被分解，并可能会离开当前所在的 <strong>GPC（图形处理簇）</strong>。三角形的 <strong>bounding box</strong> 被用来决定哪些**光栅引擎（raster engines）**需要对其进行处理，因为每个光栅引擎负责屏幕上的多个 <strong>tile（瓦片）</strong>。 随后，三角形通过 <strong>Work Distribution Crossbar</strong> 被发送到一个或多个 GPC。此时，我们有效地将三角形分解成许多更小的任务进行处理。</p>
</li>
<li><p>在目标 <strong>SM</strong> 内的 <strong>Attribute Setup（属性设置）</strong> 阶段，会确保插值数据（例如在顶点着色器中生成的输出数据）被转换为适合像素着色器的格式。</p>
</li>
<li><p><strong>GPC（图形处理簇）</strong> 的 <strong>Raster Engine</strong> 会处理其接收到的三角形，为其负责的区域生成像素信息，并执行背面剔除和深度剔除操作。</p>
</li>
<li><p>接着，我们将像素处理任务按 32 个线程（即 8 组 <strong>2x2 像素块</strong>，quad）进行批处理。这种 <strong>2x2 像素块</strong> 是像素着色器的最小处理单位。这种划分方式允许我们计算一些导数，例如用于纹理的 MIP 映射过滤（当像素块内的纹理坐标变化剧烈时，选择更高层级的 MIP）。对于那些 2x2 像素块中采样位置并未实际覆盖三角形的线程，将会被屏蔽（例如通过 <strong>gl_HelperInvocation</strong>）。然后，像素着色任务将交由本地 SM 的某个 Warp 调度器进行管理。</p>
</li>
<li><p>像素着色线程在 <strong>Warp 调度器</strong> 中执行的调度逻辑，与顶点着色器阶段的类似。线程仍然以锁步（<strong>lock-step</strong>）方式运行，这种方式特别有用，因为它可以高效访问 <strong>像素块</strong> 内的数值（几乎零成本），因为所有线程的数据都保证在同一指令点完成计算（通过扩展如 <strong>NV_shader_thread_group</strong> 实现）</p>
<p>![The logical pipeline](&#x2F;images&#x2F;Rendering Blogs&#x2F;Profile&#x2F;GPU Logic.assets&#x2F;fermipipeline_end.png)</p>
</li>
<li><p>我们完成了吗？快了！</p>
<p>像素着色器已经完成了颜色的计算，并生成了需要写入 Render Targets 的深度值。在将这些数据交给 <strong>ROP（Render Output Unit）</strong> 子系统之前，我们需要考虑三角形的原始 API 排序（像 <code>gl_PrimitiveID</code> ?）。这是因为 <strong>ROP 子系统</strong> 本身包含多个 ROP 单元，在其中执行深度测试、与 Framebuffer 的 Blending 等任务。</p>
<p>这些操作必须是原子性的（<strong>Atomic</strong>，一次只能处理一组颜色和深度值），以确保当两个三角形覆盖同一个像素时，不会出现一个三角形的颜色与另一个三角形的深度值相结合的情况。</p>
<p>此外，NVIDIA 通常会应用内存压缩技术（<strong>Memory Compression</strong>）来降低对内存带宽的需求，从而提升“有效”带宽（详见 GTX 980 的 PDF 文档）。</p>
</li>
</ol>
<p>终于完成了！</p>
<p>我们已经成功将像素写入到渲染目标中。希望这部分信息能帮助您了解 GPU 内部的工作流和数据流。同时，这也可以帮助您理解为何与 CPU 的同步操作会对性能造成如此大的影响。</p>
<p>当 GPU 必须等待所有任务完成且没有新的工作提交时，所有硬件单元都会变为闲置状态（<strong>Idle</strong>）。当发送新的工作任务时，整个 GPU 从完全闲置状态到再次完全负载需要一些时间，尤其是对于那些规模较大的 GPU。</p>
<p>在下面的图片中，您可以看到一个 CAD 模型的渲染结果，其中不同的颜色表示了对图像贡献的不同 <strong>SM（流式多处理器）</strong> 或 <strong>Warp ID</strong>。需要注意，这种结果通常是帧间不一致的（<strong>Frame-Coherent</strong>），因为工作分配会在每一帧之间有所变化。这幅场景使用了许多 <strong>Draw Calls</strong> 渲染完成，其中一些可能是并行处理的（通过 <strong>NSIGHT</strong> 工具可以观察到这种 <strong>Draw Call</strong> 的并行性）。</p>
<p>![The logical pipeline](&#x2F;images&#x2F;Rendering Blogs&#x2F;Profile&#x2F;GPU Logic.assets&#x2F;fermipipeline_distribution.png)</p>
<h1 id="2-The-Peak-Performance-Percentage-Analysis-Method-for-Optimizing-Any-GPU-Workload"><a href="#2-The-Peak-Performance-Percentage-Analysis-Method-for-Optimizing-Any-GPU-Workload" class="headerlink" title="2 The Peak-Performance-Percentage Analysis Method for Optimizing Any GPU Workload"></a>2 The Peak-Performance-Percentage Analysis Method for Optimizing Any GPU Workload</h1><p>这篇博客介绍基于硬件指标 (hardware metrics) 的性能分析方法，帮助我们了解整个GPU的使用情况，哪些硬件单元或子单元限制了性能，以及它们的运行效率多大程度接近各自的最大吞吐量 (maximum throughput，也成为 Speed of Light <strong>SOL</strong>)。假设应用程序没有使用异步计算或异步复制队列，那么这种硬件为中心的信息可以映射回图形 API 和着色器的操作，进而为提升任何给定工作负载的 GPU 性能提供指导，如图 1 所示： </p>
<img src="/images/Rendering Blogs/Profile/GPU Logic.assets/pasted-image-0-8-1024x246.png" srcset="/img/loading.gif" lazyload alt="GPU performance data flow" style="zoom: 80%;">



<ul>
<li>如果没有任何 GPU 单元的吞吐量接近其最大吞吐量（SOL），那么我们会努力提高至少一个单元的实际吞吐量。</li>
<li>如果某个 GPU 单元的吞吐量已经接近其最大吞吐量（SOL），那么我们会找出如何从该单元中移除部分工作负载。</li>
</ul>
<p>这些硬件metrics可以使用 Nsight Graphics 的 range profiler 捕获。</p>
<h2 id="2-1-step1-Capturing-a-Frame-with-Nsight-Graphics"><a href="#2-1-step1-Capturing-a-Frame-with-Nsight-Graphics" class="headerlink" title="2.1 step1: Capturing a Frame with Nsight Graphics"></a>2.1 step1: Capturing a Frame with Nsight Graphics</h2><h2 id="2-2-step-2-Breaking-Down-the-GPU-Frame-Time"><a href="#2-2-step-2-Breaking-Down-the-GPU-Frame-Time" class="headerlink" title="2.2 step 2: Breaking Down the GPU Frame Time"></a>2.2 step 2: Breaking Down the GPU Frame Time</h2><h2 id="2-3-step-3-Profiling-a-GPU-Workload"><a href="#2-3-step-3-Profiling-a-GPU-Workload" class="headerlink" title="2.3 step 3: Profiling a GPU Workload"></a>2.3 step 3: Profiling a GPU Workload</h2><h2 id="2-4-step-4-Inspecting-the-Top-SOLs-Cache-Hit-Rates"><a href="#2-4-step-4-Inspecting-the-Top-SOLs-Cache-Hit-Rates" class="headerlink" title="2.4 step 4: Inspecting the Top SOLs &amp; Cache Hit Rates"></a>2.4 step 4: Inspecting the Top SOLs &amp; Cache Hit Rates</h2><h3 id="2-4-1-The-Per-Unit-SOL-Metrics"><a href="#2-4-1-The-Per-Unit-SOL-Metrics" class="headerlink" title="2.4.1 The Per-Unit SOL% Metrics"></a>2.4.1 The Per-Unit SOL% Metrics</h3><p>在分析工作负载时，首先要关注的是GPU每个单元的SOL%，可以理解为实际吞吐量与理论吞吐量的比值。然而，对于具有多个子单元或并行数据路径的单元，SOL% 表示所有子单元和数据路径的子 SOL 指标中的最大值。GPU 各个单元有：</p>
<ul>
<li>PD (Primitive Distributor)：加载 index-buffer，并分发图元到芯片各处（GPC，Graphics Processing Cluster）</li>
<li>VAF (Vertex Attribute Fetch)：在vertex shader启动前，加载 vertex-buffer</li>
<li>SM (Streaming Multiprocessor)：执行 shader</li>
<li>TEX：执行 SRV (shader resource view) 提取操作，以及 UAV (unordered access view，读写) 访问</li>
<li>VPC (Viewport Culling)：负责视口变换、视锥剔除以及属性的透视矫正</li>
<li>L2：每个 VRAM 分区附带的二级缓存</li>
<li>CROP：负责对渲染目标进行颜色写入和混合操作</li>
<li>ZROP：负责深度和模板测试</li>
<li>VRAM：GPU 显存</li>
</ul>
<p>现代 GPU 并不是一个简单的线性流水线（A→B→C→……），而是由互联单元组成的网络（如 SM↔TEX↔L2，SM→CROP↔L2 等）。简单的“瓶颈”计算方法（基于每个单元的固定上下游接口）不足以全面分析 GPU 性能。因此，在进行性能分析时，我们主要关注每个单元的 SOL% 指标，以确定限制性能的单元和&#x2F;或问题。下一部分将详细讨论这一方法。</p>
<h3 id="2-4-2-The-“Top-SOL-Units”"><a href="#2-4-2-The-“Top-SOL-Units”" class="headerlink" title="2.4.2 The “Top SOL Units”"></a>2.4.2 The “Top SOL Units”</h3><p>先从 TOP-5 SOL 入手</p>
<h4 id="2-4-2-1-最高-SOL-80"><a href="#2-4-2-1-最高-SOL-80" class="headerlink" title="2.4.2.1 最高 SOL% &gt; 80%"></a>2.4.2.1 最高 SOL% &gt; 80%</h4><p>如果最高 SOL% 大于 80%，这表明对应工作负载在 GPU 上运行得非常高效（接近最大吞吐量）。要进一步提高速度，可以尝试减少最高 SOL 单元的工作量，或者将其部分任务转移到其他单元。例如：</p>
<ul>
<li>如果TOP SOL 单元是 SM，且 SOL% &gt; 80%，可以尝试优化掉一些指令组，或将某些计算转换为lookup table。</li>
<li>对于受到纹理吞吐量限制的工作负载 (因为结构化缓冲区通过 TEX 单元加载)，可以考虑将 structured buffer 的加载转移为 constant buffer 加载 <a href="#%5B4%5D">[4]</a>，尤其是当着色器对 structured buffer 的访问是统一(uniformly)的 (所有线程从同一地址加载数据时)</li>
</ul>
<h4 id="2-4-2-2-最高-SOL-60"><a href="#2-4-2-2-最高-SOL-60" class="headerlink" title="2.4.2.2 最高 SOL% &lt; 60%"></a>2.4.2.2 最高 SOL% &lt; 60%</h4><p>如果最高 SOL% 小于 60%，这表明最高 SOL 单元以及所有 SOL% 更低的 GPU 单元存在以下问题：</p>
<ul>
<li><strong>利用率不足</strong>（空闲周期较多）</li>
<li><strong>运行效率低下</strong>（阻塞周期较多）</li>
<li><strong>未充分利用快速路径</strong>，原因在于分配的工作负载特性</li>
</ul>
<p>以下是一些具体的例子：</p>
<ul>
<li><strong>应用程序部分受到 CPU 限制</strong>（见第 5.1.1 节）。</li>
<li><strong>大量的 <code>Wait For Idle</code> 命令或graphics与compute模式频繁切换</strong>，导致 GPU 管道反复清空（见第 5.1.2 节）。</li>
<li><strong>TEX 从某些纹理对象提取数据</strong>，由于其格式、维度或过滤模式的设计限制，运行吞吐量降低。例如，当trilinear采样 3D 纹理时，TEX SOL% 为 50% 是正常的</li>
<li>内存子系统效率低下，包括：<ul>
<li>TEX 或 L2 单元的缓存命中率较低</li>
<li>稀疏的 VRAM 访问导致 VRAM SOL% 偏低</li>
<li>VB（顶点缓冲区）、IB（索引缓冲区）、CB（常量缓冲区）或 TEX（纹理）从系统内存而非 GPU VRAM 获取数据</li>
</ul>
</li>
<li><strong>输入装配阶段</strong>提取 32 位索引缓冲区（与 16 位索引相比，效率减半）</li>
</ul>
<p>注意：在这种情况下，我们可以使用最高 SOL% 值来估算通过减少低效因素所能达到的性能提升上限。例如，如果某工作负载的 SOL 当前为 50%，假设通过优化内部低效可以将 SOL 提高到 90%，则该工作负载的最大性能增益为 90&#x2F;50 &#x3D; 1.8 倍 &#x3D; 80%。</p>
<h4 id="2-4-2-3-最高-SOL-位于-60-80"><a href="#2-4-2-3-最高-SOL-位于-60-80" class="headerlink" title="2.4.2.3 最高 SOL% 位于 [60%, 80%]"></a>2.4.2.3 最高 SOL% 位于 [60%, 80%]</h4><p>这种情况需要结合以上两种情况分析。</p>
<h3 id="2-4-3-Secondary-SOL-Units-and-TEX-L2-Hit-Rates"><a href="#2-4-3-Secondary-SOL-Units-and-TEX-L2-Hit-Rates" class="headerlink" title="2.4.3 Secondary SOL Units and TEX &amp; L2 Hit Rates"></a>2.4.3 Secondary SOL Units and TEX &amp; L2 Hit Rates</h3><p>Nsight Range Profiler 报告前 5 个最高 SOL 单元而不仅仅是最高的一个，原因在于多个硬件单元可能会相互影响，并在一定程度上共同限制性能。因此，我们建议根据 SOL% 值手动对 SOL 单元进行聚类。<br>（在实践中，10% 的差距通常是定义这些聚类的合理范围，但为了不遗漏任何问题，建议手动完成聚类分析。）</p>
<p>我们还建议查看 <strong>TEX（L1 缓存）和 L2 缓存的命中率</strong>，这些数据可以在 Range Profiler 的“Memory”部分中找到。一般来说：</p>
<ul>
<li>命中率大于 90% 表示很好</li>
<li>70% ~90% 表示较好</li>
<li>而低于 70% 则较差（可能会显著限制性能）。</li>
</ul>
<h4 id="2-4-3-1-示例1：full-screen-HBAO-blur"><a href="#2-4-3-1-示例1：full-screen-HBAO-blur" class="headerlink" title="2.4.3.1 示例1：full-screen HBAO+ blur"></a>2.4.3.1 示例1：full-screen HBAO+ blur</h4><p>full-screen HBAO+ blur 的 top 5 SOL 单元：</p>
<table>
<thead>
<tr>
<th>SM:94.5%</th>
<th>TEX:94.5%</th>
<th>L2:37.3%</th>
<th>CROP:35.9%</th>
<th>VRAM:27.7%</th>
</tr>
</thead>
</table>
<p>注意，这个工作负载同时受到 <strong>SM</strong> 和 <strong>TEX</strong> 的限制。由于 SM 和 TEX 的 SOL% 值完全相同，可以推测 SM 的性能可能受到 SM 和 TEX 单元之间接口吞吐量的限制（可能是 SM 向 TEX 的请求，或者 TEX 返回数据到 SM 的过程）。</p>
<p>该工作负载的 <strong>TEX 缓存命中率为 88.9%</strong>，<strong>L2 缓存命中率为 87.3%</strong>。<br>有关此工作负载的详细分析，请参考附录 “<a target="_blank" rel="noopener" href="https://developer.nvidia.com/blog/the-peak-performance-analysis-method-for-optimizing-any-gpu-workload/#example1">TEX-Interface Limited Workload</a>”</p>
<h4 id="2-4-3-2-示例2：SSR"><a href="#2-4-3-2-示例2：SSR" class="headerlink" title="2.4.3.2 示例2：SSR"></a>2.4.3.2 示例2：SSR</h4><table>
<thead>
<tr>
<th>SM:49.1%</th>
<th>L2:36.8%</th>
<th>TEX:35.8%</th>
<th>VRAM:33.5%</th>
<th>CROP:0.0%</th>
</tr>
</thead>
</table>
<p>在这个工作负载中，<strong>SM 是主要瓶颈</strong>，而 <strong>L2</strong>、<strong>TEX</strong> 和 <strong>VRAM</strong> 是次要限制因素。<strong>TEX 缓存命中率为 54.6%</strong>，<strong>L2 缓存命中率为 76.4%</strong>。<br>较低的 TEX 命中率可以解释 SM 的低 SOL% 值：由于 TEX 命中率较低（很可能是因为相邻像素访问了相距较远的纹素），SM 观察到的平均 TEX 延迟高于正常值，且更难以掩盖延迟。</p>
<p>注意：在这种情况下，活跃单元实际上构成了一条依赖链：<strong>SM -&gt; TEX -&gt; L2 -&gt; VRAM</strong>。</p>
<h4 id="2-4-3-3-示例3：tiled-lighting-compute-shader"><a href="#2-4-3-3-示例3：tiled-lighting-compute-shader" class="headerlink" title="2.4.3.3 示例3：tiled-lighting compute shader"></a>2.4.3.3 示例3：tiled-lighting compute shader</h4><table>
<thead>
<tr>
<th>SM:70.4%</th>
<th>L2:67.5%</th>
<th>TEX:49.3%</th>
<th>VRAM:42.6%</th>
<th>CROP:0.0%</th>
</tr>
</thead>
</table>
<p>这个工作负载中，<strong>SM 和 L2 是主要限制因素</strong>，而 <strong>TEX 和 VRAM 是次要限制因素</strong>。<strong>TEX 缓存命中率为 64.3%</strong>，<strong>L2 缓存命中率为 85.2%</strong>。</p>
<h4 id="2-4-3-4-示例4：shadow-map-generation"><a href="#2-4-3-4-示例4：shadow-map-generation" class="headerlink" title="2.4.3.4 示例4：shadow-map generation"></a>2.4.3.4 示例4：shadow-map generation</h4><table>
<thead>
<tr>
<th>PD:31.6%</th>
<th>VRAM:19.8%</th>
<th>VPC:19.4%</th>
<th>L2:16.3%</th>
<th>VAF:12.4%</th>
</tr>
</thead>
</table>
<p>这个工作负载受到 <strong>PD（图元分发器）</strong> 的限制，且最高 SOL% 较低。在这种情况下，将索引缓冲区的格式从 32 位更改为 16 位显著提升了性能。<br>由于 TEX 并未出现在前 5 个 SOL 单元中，因此 TEX 命中率无关紧要。而 <strong>L2 缓存命中率为 62.6%</strong>。</p>
<h2 id="2-5-step-5-Understand-the-Performance-Limiters"><a href="#2-5-step-5-Understand-the-Performance-Limiters" class="headerlink" title="2.5 step 5: Understand the Performance Limiters"></a>2.5 step 5: Understand the Performance Limiters</h2><p>我们现在需要了解是什么限制了这些top-SOL单元的性能。</p>
<h3 id="2-5-1-If-the-Top-SOL-is-Low"><a href="#2-5-1-If-the-Top-SOL-is-Low" class="headerlink" title="2.5.1 If the Top SOL% is Low"></a>2.5.1 If the Top SOL% is Low</h3><p>一个工作负载可能同时受到多种病理问题的影响。下面检查以下指标的值：<strong>“Graphics&#x2F;Compute Idle%”</strong> 和 <strong>“SM Active %”</strong>。</p>
<h4 id="2-5-1-1-The-“Graphics-Compute-Idle-”-metric"><a href="#2-5-1-1-The-“Graphics-Compute-Idle-”-metric" class="headerlink" title="2.5.1.1 The “Graphics&#x2F;Compute Idle%” metric"></a>2.5.1.1 The “Graphics&#x2F;Compute Idle%” metric</h4><p><strong>“Graphics&#x2F;Compute Idle%”</strong> 是指在当前工作负载中，整个图形与计算硬件管线完全空闲的 GPU 总运行周期百分比。这些周期表示图形&#x2F;计算管线为空的时间，可能是因为以下原因之一：</p>
<ol>
<li><strong>CPU 无法足够快地向 GPU 提供指令</strong>。</li>
<li>应用程序正在使用同步 Copy Engine（这可能发生在 DIRECT 队列或即时上下文中调用 Copy 操作时）。</li>
</ol>
<p>**注意：**由于 <code>Wait For Idle</code> 命令导致的管线清空不计入 “Graphics&#x2F;Compute Idle”</p>
<p>在这种情况下，我们建议测量每个工作负载中以下 CPU 调用所消耗的总 CPU 时间，并尝试优化最耗时的部分：</p>
<ul>
<li>对于 DX11<ul>
<li><code>Flush&#123;,1&#125;</code></li>
<li><code>Map</code></li>
<li><code>UpdateSubresource&#123;,1&#125;</code></li>
</ul>
</li>
<li>对于 DX12：<ul>
<li><code>Wait</code></li>
<li><code>ExecuteCommandLists</code></li>
</ul>
</li>
<li>适用于 DX11 和 DX12：所有的 <code>Create</code> 或 <code>Release</code> 调用</li>
</ul>
<p>DX11 注意事项：</p>
<ol>
<li><strong><code>ID3D11DeviceContext::Flush</code></strong><ul>
<li>调用 <code>Flush</code> 强制启动命令缓冲区，可能导致 CPU 等待。</li>
</ul>
</li>
<li><strong><code>ID3D11DeviceContext::Map</code>（针对 STAGING 资源）</strong><ul>
<li>如果连续帧中映射了相同的 STAGING 资源，可能因资源争用导致 CPU 阻塞。在这种情况下，当前帧的 <code>Map</code> 调用必须等待之前帧的处理完成。</li>
</ul>
</li>
<li><strong><code>ID3D11DeviceContext::Map</code>（使用 DX11_MAP_WRITE_DISCARD）</strong><ul>
<li>如果驱动程序耗尽了版本化空间（versioning space），<code>Map</code> 调用可能导致 CPU 阻塞。因为每次 <code>Map(WRITE_DISCARD)</code> 调用都会从固定大小的内存池返回一个新指针。当内存池耗尽时，<code>Map</code> 调用会等待。</li>
</ul>
</li>
</ol>
<p>DX12 注意事项：</p>
<ol>
<li><strong><code>ExecuteCommandLists</code>（ECL）调用</strong><ul>
<li>每次 <code>ECL</code> 调用都存在一些与启动新命令缓冲区相关的 GPU 空闲开销。</li>
<li>为减少 GPU 空闲时间，建议将所有命令列表批处理为尽可能少的 <code>ECL</code> 调用，除非需要在帧的某些点强制启动命令缓冲区（例如，在 VR 应用中减少输入延迟，保持单帧在飞行状态时）。</li>
</ul>
</li>
<li><strong><code>ID3D12CommandQueue::Wait</code> 调用</strong><ul>
<li>当应用调用 <code>Wait</code> 等待某个栅栏时，操作系统（Windows 10）会暂停向该命令队列提交新命令缓冲区，直到 <code>Wait</code> 调用返回。</li>
</ul>
</li>
</ol>
<p>**注意：**通过 Nsight 可以测量每个 API 调用的 CPU 和 GPU 时间，这些数据会在每次启动 Range Profiler 时显示在 API 统计视图中。</p>
<h4 id="2-5-1-2-The-“SM-Active-”-metric"><a href="#2-5-1-2-The-“SM-Active-”-metric" class="headerlink" title="2.5.1.2 The “SM Active%” metric"></a>2.5.1.2 The “SM Active%” metric</h4><h4 id="2-5-1-3-GPU-Trace"><a href="#2-5-1-3-GPU-Trace" class="headerlink" title="2.5.1.3 GPU Trace"></a>2.5.1.3 GPU Trace</h4><h3 id="2-5-2-If-the-Top-SOL-Unit-is-the-SM"><a href="#2-5-2-If-the-Top-SOL-Unit-is-the-SM" class="headerlink" title="2.5.2 If the Top SOL Unit is the SM"></a>2.5.2 If the Top SOL Unit is the SM</h3><h4 id="2-5-2-1-Case-1-“SM-Throughput-For-Active-Cycles”-80"><a href="#2-5-2-1-Case-1-“SM-Throughput-For-Active-Cycles”-80" class="headerlink" title="2.5.2.1 Case 1: “SM Throughput For Active Cycles” &gt; 80%"></a>2.5.2.1 Case 1: “SM Throughput For Active Cycles” &gt; 80%</h4><h4 id="2-5-2-2-Case-2-“SM-Throughput-For-Active-Cycles”-60"><a href="#2-5-2-2-Case-2-“SM-Throughput-For-Active-Cycles”-60" class="headerlink" title="2.5.2.2 Case 2: “SM Throughput For Active Cycles” &lt; 60%"></a>2.5.2.2 Case 2: “SM Throughput For Active Cycles” &lt; 60%</h4><h4 id="2-5-2-3-Case-3-SM-Throughput-For-Active-Cycles-in-60-80"><a href="#2-5-2-3-Case-3-SM-Throughput-For-Active-Cycles-in-60-80" class="headerlink" title="2.5.2.3 Case 3: SM Throughput For Active Cycles % in [60,80]"></a>2.5.2.3 Case 3: SM Throughput For Active Cycles % in [60,80]</h4><h3 id="2-5-3-If-the-Top-SOL-unit-is-not-the-SM"><a href="#2-5-3-If-the-Top-SOL-unit-is-not-the-SM" class="headerlink" title="2.5.3 If the Top SOL unit is not the SM"></a>2.5.3 If the Top SOL unit is not the SM</h3><h4 id="2-5-3-1-If-the-Top-SOL-unit-is-TEX-L2-or-VRAM"><a href="#2-5-3-1-If-the-Top-SOL-unit-is-TEX-L2-or-VRAM" class="headerlink" title="2.5.3.1 If the Top SOL unit is TEX, L2, or VRAM"></a>2.5.3.1 If the Top SOL unit is TEX, L2, or VRAM</h4><h4 id="2-5-3-2-If-the-Top-SOL-unit-is-CROP-or-ZROP"><a href="#2-5-3-2-If-the-Top-SOL-unit-is-CROP-or-ZROP" class="headerlink" title="2.5.3.2 If the Top SOL unit is CROP or ZROP"></a>2.5.3.2 If the Top SOL unit is CROP or ZROP</h4><h4 id="2-5-3-3-If-the-Top-SOL-unit-is-PD"><a href="#2-5-3-3-If-the-Top-SOL-unit-is-PD" class="headerlink" title="2.5.3.3 If the Top SOL unit is PD"></a>2.5.3.3 If the Top SOL unit is PD</h4><h4 id="2-5-3-4-If-the-Top-SOL-unit-is-VAF"><a href="#2-5-3-4-If-the-Top-SOL-unit-is-VAF" class="headerlink" title="2.5.3.4 If the Top SOL unit is VAF"></a>2.5.3.4 If the Top SOL unit is VAF</h4><h1 id="3-Optimizing-VK-VKR-and-DX12-DXR-Applications-Using-Nsight-Graphics-GPU-Trace-Advanced-Mode-Metrics"><a href="#3-Optimizing-VK-VKR-and-DX12-DXR-Applications-Using-Nsight-Graphics-GPU-Trace-Advanced-Mode-Metrics" class="headerlink" title="3 Optimizing VK&#x2F;VKR and DX12&#x2F;DXR Applications Using Nsight Graphics: GPU Trace Advanced Mode Metrics"></a>3 Optimizing VK&#x2F;VKR and DX12&#x2F;DXR Applications Using Nsight Graphics: GPU Trace Advanced Mode Metrics</h1><h2 id="3-1-Capturing-GPU-Trace-data-with-Advanced-Mode-Metrics"><a href="#3-1-Capturing-GPU-Trace-data-with-Advanced-Mode-Metrics" class="headerlink" title="3.1 Capturing GPU Trace data with Advanced Mode Metrics"></a>3.1 Capturing GPU Trace data with Advanced Mode Metrics</h2><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><p><a name="[1]">[1]</a> <a target="_blank" rel="noopener" href="https://developer.nvidia.com/content/life-triangle-nvidias-logical-pipeline">https://developer.nvidia.com/content/life-triangle-nvidias-logical-pipeline</a></p>
<p><a name="[2]">[2]</a> <a target="_blank" rel="noopener" href="https://developer.nvidia.com/blog/the-peak-performance-analysis-method-for-optimizing-any-gpu-workload/">https://developer.nvidia.com/blog/the-peak-performance-analysis-method-for-optimizing-any-gpu-workload/</a></p>
<p><a name="[3]">[3]</a> <a target="_blank" rel="noopener" href="https://developer.nvidia.com/blog/optimizing-vk-vkr-and-dx12-dxr-applications-using-nsight-graphics-gpu-trace-advanced-mode-metrics/">https://developer.nvidia.com/blog/optimizing-vk-vkr-and-dx12-dxr-applications-using-nsight-graphics-gpu-trace-advanced-mode-metrics/</a></p>
<p><a name="[4]">[4]</a> [Structured Buffer Performance](.&#x2F;Structured Buffer Performance.md)</p>

                
              </div>
            
            <hr/>
            <div>
              <div class="post-metas my-3">
  
    <div class="post-meta mr-3 d-flex align-items-center">
      <i class="iconfont icon-category"></i>
      

<span class="category-chains">
  
  
    
      <span class="category-chain">
        
  <a href="/categories/Rendering-Blogs/" class="category-chain-item">Rendering Blogs</a>
  
  
    <span>></span>
    
  <a href="/categories/Rendering-Blogs/Profile/" class="category-chain-item">Profile</a>
  
  

  

      </span>
    
  
</span>

    </div>
  
  
</div>


              
  

  <div class="license-box my-3">
    <div class="license-title">
      <div>GPU Logic</div>
      <div>http://example.com/2024/11/22/Rendering Blogs/Profile/GPU Logic/</div>
    </div>
    <div class="license-meta">
      
        <div class="license-meta-item">
          <div>Author</div>
          <div>John Doe</div>
        </div>
      
      
        <div class="license-meta-item license-meta-date">
          <div>Posted on</div>
          <div>November 22, 2024</div>
        </div>
      
      
      
        <div class="license-meta-item">
          <div>Licensed under</div>
          <div>
            
              
              
                <a class="print-no-link" target="_blank" href="https://creativecommons.org/licenses/by/4.0/">
                  <span class="hint--top hint--rounded" aria-label="BY - Attribution">
                    <i class="iconfont icon-cc-by"></i>
                  </span>
                </a>
              
            
          </div>
        </div>
      
    </div>
    <div class="license-icon iconfont"></div>
  </div>



              
                <div class="post-prevnext my-3">
                  <article class="post-prev col-6">
                    
                    
                      <a href="/2024/11/24/Rendering%20Blogs/Profile/Structured%20Buffer%20Performance/" title="">
                        <i class="iconfont icon-arrowleft"></i>
                        <span class="hidden-mobile"></span>
                        <span class="visible-mobile">Previous</span>
                      </a>
                    
                  </article>
                  <article class="post-next col-6">
                    
                    
                      <a href="/2024/10/14/Rendering%20Blogs/Graphics%20Basis/Disney%20Principled%20BRDF/" title="Disney BRDF">
                        <span class="hidden-mobile">Disney BRDF</span>
                        <span class="visible-mobile">Next</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </article>
                </div>
              
            </div>

            
          </article>
        </div>
      </div>
    </div>

    <div class="side-col d-none d-lg-block col-lg-2">
      
  <aside class="sidebar" style="margin-left: -1rem">
    <div id="toc">
  <p class="toc-header">
    <i class="iconfont icon-list"></i>
    <span>Table of Contents</span>
  </p>
  <div class="toc-body" id="toc-body"></div>
</div>



  </aside>


    </div>
  </div>
</div>





  



  



  



  



  







    

    
      <a id="scroll-top-button" aria-label="TOP" href="#" role="button">
        <i class="iconfont icon-arrowup" aria-hidden="true"></i>
      </a>
    

    
      <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">Search</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v" for="local-search-input">Keyword</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>

    

    
  </main>

  <footer>
    <div class="footer-inner">
  
    <div class="footer-content">
       <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a> <i class="iconfont icon-love"></i> <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"><span>Fluid</span></a> 
    </div>
  
  
  
</div>

  </footer>

  <!-- Scripts -->
  
  <script  src="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.js" ></script>
  <link  rel="stylesheet" href="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.css" />

  <script>
    NProgress.configure({"showSpinner":false,"trickleSpeed":100})
    NProgress.start()
    window.addEventListener('load', function() {
      NProgress.done();
    })
  </script>


<script  src="https://lib.baomitu.com/jquery/3.6.4/jquery.min.js" ></script>
<script  src="https://lib.baomitu.com/twitter-bootstrap/4.6.1/js/bootstrap.min.js" ></script>
<script  src="/js/events.js" ></script>
<script  src="/js/plugins.js" ></script>


  <script  src="https://lib.baomitu.com/typed.js/2.0.12/typed.min.js" ></script>
  <script>
    (function (window, document) {
      var typing = Fluid.plugins.typing;
      var subtitle = document.getElementById('subtitle');
      if (!subtitle || !typing) {
        return;
      }
      var text = subtitle.getAttribute('data-typed-text');
      
        typing(text);
      
    })(window, document);
  </script>




  
    <script  src="/js/img-lazyload.js" ></script>
  




  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/tocbot/4.20.1/tocbot.min.js', function() {
    var toc = jQuery('#toc');
    if (toc.length === 0 || !window.tocbot) { return; }
    var boardCtn = jQuery('#board-ctn');
    var boardTop = boardCtn.offset().top;

    window.tocbot.init(Object.assign({
      tocSelector     : '#toc-body',
      contentSelector : '.markdown-body',
      linkClass       : 'tocbot-link',
      activeLinkClass : 'tocbot-active-link',
      listClass       : 'tocbot-list',
      isCollapsedClass: 'tocbot-is-collapsed',
      collapsibleClass: 'tocbot-is-collapsible',
      scrollSmooth    : true,
      includeTitleTags: true,
      headingsOffset  : -boardTop,
    }, CONFIG.toc));
    if (toc.find('.toc-list-item').length > 0) {
      toc.css('visibility', 'visible');
    }

    Fluid.events.registerRefreshCallback(function() {
      if ('tocbot' in window) {
        tocbot.refresh();
        var toc = jQuery('#toc');
        if (toc.length === 0 || !tocbot) {
          return;
        }
        if (toc.find('.toc-list-item').length > 0) {
          toc.css('visibility', 'visible');
        }
      }
    });
  });
</script>


  <script src=https://lib.baomitu.com/clipboard.js/2.0.11/clipboard.min.js></script>

  <script>Fluid.plugins.codeWidget();</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/anchor-js/5.0.0/anchor.min.js', function() {
    window.anchors.options = {
      placement: CONFIG.anchorjs.placement,
      visible  : CONFIG.anchorjs.visible
    };
    if (CONFIG.anchorjs.icon) {
      window.anchors.options.icon = CONFIG.anchorjs.icon;
    }
    var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
    var res = [];
    for (var item of el) {
      res.push('.markdown-body > ' + item.trim());
    }
    if (CONFIG.anchorjs.placement === 'left') {
      window.anchors.options.class = 'anchorjs-link-left';
    }
    window.anchors.add(res.join(', '));

    Fluid.events.registerRefreshCallback(function() {
      if ('anchors' in window) {
        anchors.removeAll();
        var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
        var res = [];
        for (var item of el) {
          res.push('.markdown-body > ' + item.trim());
        }
        if (CONFIG.anchorjs.placement === 'left') {
          anchors.options.class = 'anchorjs-link-left';
        }
        anchors.add(res.join(', '));
      }
    });
  });
</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js', function() {
    Fluid.plugins.fancyBox();
  });
</script>


  <script>Fluid.plugins.imageCaption();</script>

  <script  src="/js/local-search.js" ></script>





<!-- 主题的启动项，将它保持在最底部 -->
<!-- the boot of the theme, keep it at the bottom -->
<script  src="/js/boot.js" ></script>


  

  <noscript>
    <div class="noscript-warning">Blog works best with JavaScript enabled</div>
  </noscript>
</body>
</html>
